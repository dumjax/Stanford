{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data organizer stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/custom_keras/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using Theano backend.\n",
      "Using gpu device 0: GRID K520 (CNMeM is disabled, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import mkdir, listdir, makedirs\n",
    "from os.path import join, abspath, basename, splitext, dirname, isdir\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "from json import load, dump\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from PIL.Image import LANCZOS\n",
    "from PIL.ImageOps import fit\n",
    "from keras.preprocessing.image import load_img, ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Convolution2D \n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Input\n",
    "from keras.models import model_from_json\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "import threading\n",
    "import random\n",
    "from random import shuffle\n",
    "from itertools import combinations, chain, product, izip\n",
    "from math import ceil\n",
    "from utils import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IMGS_DIM_3D = (3, 256, 256)\n",
    "IMGS_DIM_2D = IMGS_DIM_3D[1:]\n",
    "\n",
    "DATA_DIR = '/data/paintersbynumbers/'\n",
    "\n",
    "TRAIN_DIR = join(DATA_DIR, 'train')\n",
    "TEST_DIR = join(DATA_DIR, 'test')\n",
    "TRAIN_INFO_FILE = join(DATA_DIR, 'train_info.csv')\n",
    "TEST_X_FILE = join(DATA_DIR, 'submission_info.csv')\n",
    "TEST_Y_FILE = join(DATA_DIR, 'solution_painter.csv')\n",
    "\n",
    "ORGANIZED_DATA_INFO_FILE = 'organized_data_info_.json'\n",
    "MODELS_DIR = join(DATA_DIR, 'models/siamese')\n",
    "NEW_TRAIN_DIR = join(DATA_DIR, 'train_{:d}'.format(IMGS_DIM_2D[0]))\n",
    "NEW_VAL_DIR = join(DATA_DIR, 'val_{:d}'.format(IMGS_DIM_2D[0]))\n",
    "NEW_TEST_DIR = join(DATA_DIR, 'test_{:d}'.format(IMGS_DIM_2D[0]))\n",
    "NEW_TEST_DIR = join(NEW_TEST_DIR, 'all')\n",
    "NEW_TEST_GEN_DIR = join(DATA_DIR, 'test_{:d}_gen'.format(IMGS_DIM_2D[0]))\n",
    "        \n",
    "VAL_SIZE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# _organize_train_dir()\n",
    "# _organize_test_dir()\n",
    "\n",
    "def _organize_train_dir():\n",
    "    paths, labels = _load_paths_labels_from_train_dir()\n",
    "    ind_tr, ind_val, classes = _train_val_split_indices(labels)\n",
    "    _save_images_to_dir(NEW_TRAIN_DIR, paths[ind_tr], labels[ind_tr], classes)\n",
    "    _save_images_to_dir(NEW_VAL_DIR, paths[ind_val], labels[ind_val], classes)\n",
    "    \n",
    "def _load_paths_labels_from_train_dir():\n",
    "    labels_lookup = load_train_info()\n",
    "    paths, labels = [], []\n",
    "    for name in listdir(TRAIN_DIR):\n",
    "        abspath_ = abspath(join(TRAIN_DIR, name))\n",
    "        paths.append(abspath_)\n",
    "        labels.append(labels_lookup[name])\n",
    "\n",
    "    return np.array(paths), LabelEncoder().fit_transform(labels)\n",
    "\n",
    "def load_train_info():\n",
    "    train_info = read_lines(TRAIN_INFO_FILE)[1:]\n",
    "    parsed_train_info = {}\n",
    "    # filename,artist,title,style,genre,date\n",
    "    for l in train_info:\n",
    "        split = l.split(',')\n",
    "        parsed_train_info[split[0]] = split[1]\n",
    "    return parsed_train_info\n",
    "\n",
    "def _train_val_split_indices(labels):\n",
    "    split = StratifiedShuffleSplit(labels, n_iter=1, test_size=VAL_SIZE, random_state=42)\n",
    "    indices_tr, indices_val = next(iter(split))\n",
    "    \n",
    "    return indices_tr, indices_val, split.classes\n",
    "\n",
    "def _save_organized_data_info(classes, indices_tr, indices_val):\n",
    "    info = {\n",
    "        'dir_tr': NEW_TRAIN_DIR,\n",
    "        'num_tr': len(indices_tr),\n",
    "        'dir_val': NEW_VAL_DIR,\n",
    "        'num_val': len(indices_val),\n",
    "        'num_distinct_cls': len(classes),\n",
    "    }\n",
    "    save_organized_data_info(info, IMGS_DIM_2D[0])\n",
    "\n",
    "def save_organized_data_info(info, imgs_dim_1d):\n",
    "    with open(_organized_data_info_file_dim(imgs_dim_1d), 'w') as f:\n",
    "        dump(info, f)\n",
    "\n",
    "def load_organized_data_info(imgs_dim_1d):\n",
    "    with open(_organized_data_info_file_dim(imgs_dim_1d), 'r') as f:\n",
    "        return load(f)\n",
    "    \n",
    "def _organized_data_info_file_dim(imgs_dim_1d):\n",
    "    split = ORGANIZED_DATA_INFO_FILE.split('.')\n",
    "    split[0] += str(imgs_dim_1d)\n",
    "    return join(DATA_DIR, '.'.join(split))\n",
    "\n",
    "def _save_images_to_dir(dest_dir, src_paths, labels, distinct_classes):\n",
    "\n",
    "    _make_dir_tree(dest_dir, distinct_classes)\n",
    "\n",
    "    for src_path, label in zip(src_paths, labels):\n",
    "        dest_path = join(join(dest_dir, str(label)), basename(src_path))\n",
    "        scaled_cropped_image = _save_scaled_cropped_img(src_path, dest_path)\n",
    "        \n",
    "def _make_dir_tree(dir_, classes):\n",
    "    mkdir(dir_)\n",
    "    for class_ in classes:\n",
    "        class_dir = join(dir_, str(class_))\n",
    "        mkdir(class_dir)\n",
    "        \n",
    "def _save_scaled_cropped_img(src, dest):\n",
    "    image = load_img(src)\n",
    "    image = fit(image, IMGS_DIM_2D, method=LANCZOS)\n",
    "    image.save(dest)\n",
    "    return image\n",
    "\n",
    "def _organize_test_dir():\n",
    "    makedirs(NEW_TEST_DIR)\n",
    "\n",
    "    num_test_samples = 0\n",
    "    for name in listdir(TEST_DIR):\n",
    "        src_path = abspath(join(TEST_DIR, name))\n",
    "        dest_path = join(NEW_TEST_DIR, name)\n",
    "        try:\n",
    "            _save_scaled_cropped_img(src_path, dest_path)\n",
    "            num_test_samples += 1\n",
    "        except IOError:\n",
    "            pass\n",
    "\n",
    "    _append_num_te_to_organized_data_info(num_test_samples)\n",
    "    \n",
    "def _append_num_te_to_organized_data_info(num_test_samples):\n",
    "    data_info = load_organized_data_info(IMGS_DIM_2D[0])\n",
    "    data_info['dir_te'] = dirname(NEW_TEST_DIR)\n",
    "    data_info['num_te'] = num_test_samples\n",
    "    save_organized_data_info(data_info, IMGS_DIM_2D[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# _organize_train_dir()\n",
    "# _organize_test_dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data provider stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generators(dir_tr, dir_val, dir_te, batch_size, num_samples_per_cls=1, num_samples_per_cls_val=None):\n",
    "\n",
    "    gen_tr = PairsImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        rotation_range=180,\n",
    "        zoom_range=0.2,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.3,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='reflect'\n",
    "    )\n",
    "    \n",
    "    gen_val = PairsImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "\n",
    "    sample = np.array(apply_to_images_in_subdirs(dir_tr, load_img_arr, num_samples_per_cls=num_samples_per_cls))\n",
    "    gen_tr.fit(sample)\n",
    "    gen_val.fit(sample)\n",
    "\n",
    "    gen_tr = gen_tr.flow_from_directory(dir_tr, batch_size=batch_size)\n",
    "    \n",
    "    gen_val = gen_val.flow_from_directory(dir_val, batch_size=batch_size, num_samples_per_cls=num_samples_per_cls_val)\n",
    "    \n",
    "    if dir_te is not None:\n",
    "        gen_te = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "        gen_te.fit(sample)\n",
    "        num_test_samples = load_organized_data_info(IMGS_DIM_2D[0])['num_te']\n",
    "        batch_size=18\n",
    "        gen_te = gen_te.flow_from_directory(dir_te, class_mode=None, batch_size=batch_size, \n",
    "                                            target_size=IMGS_DIM_2D, shuffle=False, save_format='jpg',\n",
    "                                           save_to_dir=NEW_TEST_GEN_DIR, save_prefix='aug')   \n",
    "        num_runs = 0\n",
    "        for X in gen_te:\n",
    "            num_runs+=1\n",
    "            if num_runs == num_test_samples/batch_size:\n",
    "                break\n",
    "                \n",
    "        for fn in os.listdir(NEW_TEST_GEN_DIR):\n",
    "            fn = join(NEW_TEST_GEN_DIR, fn)\n",
    "            if os.path.isfile(fn):\n",
    "                new_fn = join(NEW_TEST_GEN_DIR, fn.split('_')[-1])\n",
    "                os.rename(fn, new_fn)\n",
    "\n",
    "    return gen_tr, gen_val\n",
    "    \n",
    "class PairsImageDataGenerator(ImageDataGenerator):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(PairsImageDataGenerator, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def flow(self, X, y=None, batch_size=32, shuffle=True, seed=None,\n",
    "             save_to_dir=None, save_prefix='', save_format='jpg', num_samples_per_cls=None):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def flow_from_directory(\n",
    "            self, dir_, target_size=IMGS_DIM_2D, color_mode='rgb',\n",
    "            classes=None, class_mode='categorical', batch_size=32,\n",
    "            shuffle=True, seed=None, save_to_dir=None, save_prefix='',\n",
    "            save_format='jpg', num_samples_per_cls=None):\n",
    "\n",
    "        return PairsDirectoryIterator(\n",
    "            dir_, self, batch_size, num_samples_per_cls)\n",
    "\n",
    "class PairsDirectoryIterator(object):\n",
    "\n",
    "    def __init__(self, dir_, image_data_generator,\n",
    "                 batch_size=32, num_samples_per_cls=None):\n",
    "    \n",
    "        self.dir_ = dir_\n",
    "        self.paths, self.y = self._get_paths_labels_from_dir(dir_, num_samples_per_cls)\n",
    "        self.batch_size = batch_size\n",
    "        self._init_pairs_generator()\n",
    "        self.image_data_generator = image_data_generator\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_paths_labels_from_dir(dir_, num_per_cls):\n",
    "        def path_label(p): return [p, basename(dirname(p))]\n",
    "        paths_labels = apply_to_images_in_subdirs(dir_, path_label, num_samples_per_cls=num_per_cls)\n",
    "        paths_labels = np.array(paths_labels)\n",
    "        return paths_labels[:, 0], paths_labels[:, 1].astype(int)\n",
    "\n",
    "    def _init_pairs_generator(self):\n",
    "        self.pairs_generator = alt_pairs_generator(self.dir_, self.batch_size, lambda a, b: [a, b])\n",
    "\n",
    "    def iter(self):\n",
    "        return self\n",
    "\n",
    "    def next(self):\n",
    "        with self.lock:\n",
    "            try:\n",
    "                paths_batch, y_batch = next(self.pairs_generator)\n",
    "            except StopIteration:\n",
    "                self._init_pairs_generator()\n",
    "                paths_batch, y_batch = next(self.pairs_generator)\n",
    "\n",
    "        X_batch = []\n",
    "        for path_a, path_b in paths_batch:\n",
    "            image_a, image_b = load_img_arr(path_a), load_img_arr(path_b)\n",
    "            image_a = self._std_random_transform_img(image_a)\n",
    "            image_b = self._std_random_transform_img(image_b)\n",
    "            X_batch.append([image_a, image_b])\n",
    "        X_batch = np.array(X_batch)\n",
    "\n",
    "        return [X_batch[:, 0], X_batch[:, 1]], y_batch\n",
    "    \n",
    "    def _std_random_transform_img(self, img):\n",
    "        img = self.image_data_generator.random_transform(img)\n",
    "        return self.image_data_generator.standardize(img)\n",
    "\n",
    "def pairs_generator(X, y, batch_size, pair_func):\n",
    "    \n",
    "    hard_positive_mining=True\n",
    "    \n",
    "    singles = range(y.shape[0])\n",
    "    shuffle(singles)\n",
    "    pairs = combinations(singles, 2)\n",
    "    \n",
    "    while True:\n",
    "        X_batch, y_batch = [], []\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            try:\n",
    "                pair_indices = next(pairs)\n",
    "            except StopIteration:\n",
    "                return\n",
    "            index_a, index_b = int(pair_indices[0]), int(pair_indices[1])\n",
    "            X_batch.append(pair_func(X[index_a], X[index_b]))\n",
    "            y_batch.append(int(y[index_a] != y[index_b]))\n",
    "            \n",
    "        X_batch = np.array(X_batch)\n",
    "        y_batch = np.array(y_batch)\n",
    "            \n",
    "        yield X_batch, y_batch\n",
    "\n",
    "def alt_pairs_generator(dir_, batch_size, pair_func):\n",
    "        \n",
    "    data_info = load_organized_data_info(IMGS_DIM_2D[0])\n",
    "    classes = range(data_info['num_distinct_cls'])\n",
    "    \n",
    "    negative_pairs = combinations(classes, 2)\n",
    "    positive_pairs = izip(classes, classes)\n",
    "    \n",
    "    while True:\n",
    "        X_batch, y_batch = [], []\n",
    "        \n",
    "        for i in range(batch_size/2):\n",
    "            \n",
    "            pairs = []\n",
    "            try:\n",
    "                pairs.append(next(positive_pairs))\n",
    "                pairs.append(next(negative_pairs))\n",
    "            except StopIteration:\n",
    "                return\n",
    "            \n",
    "            for pair in pairs:\n",
    "                class_a, class_b = int(pair[0]), int(pair[1])     \n",
    "                \n",
    "                subdir_a = join(dir_, str(class_a))\n",
    "                subdir_b = join(dir_, str(class_b))\n",
    "                \n",
    "                images_a = [os.path.join(subdir_a, f) for f in os.listdir(subdir_a) \n",
    "                            if os.path.isfile(os.path.join(subdir_a, f))]\n",
    "                images_b = [os.path.join(subdir_b, f) for f in os.listdir(subdir_b) \n",
    "                            if os.path.isfile(os.path.join(subdir_b, f))]\n",
    "                \n",
    "                if len(images_a) > 0 and len(images_b) > 0:\n",
    "                    x_a = random.choice(images_a)\n",
    "                    x_b = random.choice(images_b)              \n",
    "                \n",
    "                    X_batch.append(pair_func(x_a, x_b))\n",
    "                    y_batch.append(float(class_a != class_b))\n",
    "                    \n",
    "        X_batch = np.array(X_batch)\n",
    "        y_batch = np.array(y_batch)\n",
    "                    \n",
    "        yield X_batch, y_batch\n",
    "\n",
    "def apply_to_images_in_subdirs(parent_dir, func, num_samples_per_cls=None, **kwargs):\n",
    "    results = []\n",
    "    for cls_dir_name in listdir(parent_dir):\n",
    "        cls_dir = abspath(join(parent_dir, cls_dir_name))\n",
    "        r = _apply_to_first_n_in_dir(func, cls_dir, num_samples_per_cls, **kwargs)\n",
    "        results += r\n",
    "    return results\n",
    "\n",
    "def _apply_to_first_n_in_dir(func, dir_, num_samples_per_cls, **kwargs):\n",
    "    if not isdir(dir_):\n",
    "        return []\n",
    "    results = []\n",
    "    for path in listdir(dir_)[:num_samples_per_cls]:\n",
    "        abspath_ = abspath(join(dir_, path))\n",
    "        result = func(abspath_, **kwargs)\n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "MAX_EPOCHS = 10\n",
    "TRAIN_SAMPLES_PER_EPOCH = 1000\n",
    "VAL_SAMPLES_PER_EPOCH = 100\n",
    "# TEST_SAMPLES_TOTAL = 10\n",
    "\n",
    "# MAX_EPOCHS = 100\n",
    "# TRAIN_SAMPLES_PER_EPOCH = data_info['num_tr']\n",
    "# VAL_SAMPLES_PER_EPOCH = data_info['num_val']\n",
    "# TEST_SAMPLES_TOTAL = data_info['num_te']/100\n",
    "\n",
    "NUM_SAMPLES_PER_CLS = 1\n",
    "\n",
    "data_info = load_organized_data_info(IMGS_DIM_2D[0])\n",
    "dir_tr = data_info['dir_tr']\n",
    "dir_val = data_info['dir_val']\n",
    "dir_te = data_info['dir_te']\n",
    "\n",
    "def build_siamese_net():\n",
    "    \n",
    "    print \"Building siamese net\"\n",
    "\n",
    "    processor = _shared_net(full=False)\n",
    "\n",
    "    input_1 = Input(shape=IMGS_DIM_3D)\n",
    "    input_2 = Input(shape=IMGS_DIM_3D)\n",
    "\n",
    "    processed_1 = processor(input_1)\n",
    "    processed_2 = processor(input_2)\n",
    "\n",
    "    distance = Lambda(_euclidean_distance, output_shape=_eucl_dist_output_shape)([processed_1, processed_2])\n",
    "\n",
    "    model = Model(input=[input_1, input_2], output=distance)\n",
    "    \n",
    "    rms = RMSprop(lr=1e-5)\n",
    "    model.compile(loss=_contrastive_loss, optimizer='rmsprop')\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model():\n",
    "        \n",
    "    print \"Training model\"\n",
    "    \n",
    "    hist = model.fit_generator(\n",
    "        generator=gen_tr,\n",
    "        nb_epoch=MAX_EPOCHS,\n",
    "        samples_per_epoch=TRAIN_SAMPLES_PER_EPOCH,\n",
    "        validation_data=gen_val,\n",
    "        nb_val_samples=VAL_SAMPLES_PER_EPOCH,\n",
    "        callbacks=[ModelCheckpoint(model_fname + '_checkpoint', save_best_only=True)],\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    return hist\n",
    "    \n",
    "def _shared_net(full=False):\n",
    "        \n",
    "    print \"Building shared net\"\n",
    "\n",
    "    nb_filters = 32\n",
    "    nb_pool = 2\n",
    "    nb_conv = 3\n",
    "    \n",
    "    if full:\n",
    "    \n",
    "        seq = Sequential()\n",
    "        seq.add(Dense(128, input_shape=IMGS_DIM_3D, activation='relu'))\n",
    "        seq.add(Dropout(0.1))\n",
    "        seq.add(Dense(128, activation='relu'))\n",
    "        seq.add(Dropout(0.1))\n",
    "        seq.add(Dense(128, activation='relu'))\n",
    "        model = seq\n",
    "        \n",
    "    else:\n",
    "        model = Sequential()\n",
    "        model.add(Convolution2D(nb_filters, nb_conv, nb_conv,  activation='relu',\n",
    "                                input_shape=IMGS_DIM_3D, border_mode='valid'))\n",
    "        model.add(BatchNormalization(axis=1, mode=2))\n",
    "        model.add(Convolution2D(nb_filters, nb_conv, nb_conv, activation='relu'))\n",
    "        model.add(BatchNormalization(axis=1, mode=2))\n",
    "        model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "        model.add(Dropout(p=0.1))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(64, input_shape=IMGS_DIM_3D, activation='relu'))\n",
    "        model.add(BatchNormalization(mode=2))        \n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(BatchNormalization(mode=2))     \n",
    "    \n",
    "    return model\n",
    "\n",
    "def _euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
    "\n",
    "def _eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return shape1\n",
    "                  \n",
    "def _contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
    "\n",
    "def compute_accuracy(y_pred, y_true):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return y_true[y_pred.ravel() < 0.5].mean()\n",
    "\n",
    "def test_model():\n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    test_indices = []\n",
    "    \n",
    "    num_tests = 0\n",
    "    batch_size=32\n",
    "    for batch in read_lines_in_batches(TEST_X_FILE, batch_size):\n",
    "        X=[]\n",
    "        for line in batch:\n",
    "            ind = int(line[0])\n",
    "            test_indices.append(ind)\n",
    "            img_1 = join(NEW_TEST_GEN_DIR, line[1])\n",
    "            img_2 = join(NEW_TEST_GEN_DIR, line[2])\n",
    "            \n",
    "            X_1 = load_img_arr(img_1)\n",
    "            X_2 = load_img_arr(img_2)\n",
    "            X.append([X_1, X_2])\n",
    "            y_true.append(test_labels[ind])\n",
    "        X = np.array(X)\n",
    "        X = [X[:,0], X[:,1]]\n",
    "        y_pred += list(model.predict(X, batch_size=batch_size))\n",
    "        num_tests += batch_size\n",
    "        print num_tests\n",
    "        if num_tests > TEST_SAMPLES_TOTAL:\n",
    "            break\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array([y[0] for y in y_pred])\n",
    "    print y_true, y_pred\n",
    "    print compute_accuracy(y_pred, y_true)\n",
    "    return\n",
    "\n",
    "def save_model(model):\n",
    "    arch_fname = model_fname + '.arch.json'\n",
    "    weights_fname = model_fname + '.weights.h5'\n",
    "    open(arch_fname, 'w').write(model.to_json())\n",
    "    model.save_weights(weights_fname, overwrite=True)\n",
    "\n",
    "def load_model():\n",
    "    arch_fname = model_fname + '.arch.json'\n",
    "    weights_fname = model_fname + '.weights.h5'\n",
    "    model_json_string = open(arch_fname).read()\n",
    "    model=model_from_json(model_json_string)\n",
    "    model.load_weights(weights_fname)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and train siamese net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building siamese net\n",
      "Building shared net\n"
     ]
    }
   ],
   "source": [
    "model = build_siamese_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_tr, gen_val = generators(dir_tr, dir_val, None, batch_size=BATCH_SIZE, num_samples_per_cls=NUM_SAMPLES_PER_CLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n",
      "Epoch 1/10"
     ]
    }
   ],
   "source": [
    "rebuild=True\n",
    "model_fname = join(MODELS_DIR, 'siamese')\n",
    "\n",
    "if rebuild:\n",
    "#     model = build_siamese_net()\n",
    "    hist = train_model()\n",
    "    save_model(model)\n",
    "else: \n",
    "    model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_labels = {}\n",
    "batch_size=1\n",
    "for batch in read_lines_in_batches(TEST_Y_FILE, batch_size):\n",
    "    for line in batch:\n",
    "        test_labels[int(line[0])] = 1-int(float(line[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test siamese net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
