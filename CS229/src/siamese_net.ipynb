{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data organizer stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import mkdir, listdir, makedirs\n",
    "from os.path import join, abspath, basename, splitext, dirname, isdir\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "from json import load, dump\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from PIL.Image import LANCZOS\n",
    "from PIL.ImageOps import fit\n",
    "\n",
    "from keras.preprocessing.image import load_img, ImageDataGenerator\n",
    "\n",
    "from utils import read_lines, load_img_arr\n",
    "\n",
    "IMGS_DIM_2D = (256, 256)\n",
    "VAL_SIZE = 0.1\n",
    "\n",
    "DATA_DIR = '/data/paintersbynumbers/'\n",
    "\n",
    "TRAIN_DIR = join(DATA_DIR, 'train')\n",
    "TEST_DIR = join(DATA_DIR, 'test')\n",
    "TRAIN_INFO_FILE = join(DATA_DIR, 'train_info.csv')\n",
    "\n",
    "ORGANIZED_DATA_INFO_FILE = 'organized_data_info_.json'\n",
    "MODELS_DIR = join(DATA_DIR, 'models')\n",
    "NEW_TRAIN_DIR = join(DATA_DIR, 'train_{:d}'.format(IMGS_DIM_2D[0]))\n",
    "NEW_VAL_DIR = join(DATA_DIR, 'val_{:d}'.format(IMGS_DIM_2D[0]))\n",
    "NEW_TEST_DIR = join(DATA_DIR, 'test_{:d}'.format(IMGS_DIM_2D[0]))\n",
    "NEW_TEST_DIR = join(NEW_TEST_DIR, 'all')\n",
    "\n",
    "def _organize_train_dir():\n",
    "    paths, labels = _load_paths_labels_from_train_dir()\n",
    "    ind_tr, ind_val, classes = _train_val_split_indices(labels)\n",
    "    _save_images_to_dir(NEW_TRAIN_DIR, paths[ind_tr], labels[ind_tr], classes)\n",
    "    _save_images_to_dir(NEW_VAL_DIR, paths[ind_val], labels[ind_val], classes)\n",
    "    \n",
    "def _load_paths_labels_from_train_dir():\n",
    "    labels_lookup = load_train_info()\n",
    "    paths, labels = [], []\n",
    "    for name in listdir(TRAIN_DIR):\n",
    "        abspath_ = abspath(join(TRAIN_DIR, name))\n",
    "        paths.append(abspath_)\n",
    "        labels.append(labels_lookup[name])\n",
    "\n",
    "    return np.array(paths), LabelEncoder().fit_transform(labels)\n",
    "\n",
    "def load_train_info():\n",
    "    train_info = read_lines(TRAIN_INFO_FILE)[1:]\n",
    "    parsed_train_info = {}\n",
    "    # filename,artist,title,style,genre,date\n",
    "    for l in train_info:\n",
    "        split = l.split(',')\n",
    "        parsed_train_info[split[0]] = split[1]\n",
    "    return parsed_train_info\n",
    "\n",
    "def _train_val_split_indices(labels):\n",
    "    split = StratifiedShuffleSplit(labels, n_iter=1, test_size=VAL_SIZE, random_state=42)\n",
    "    indices_tr, indices_val = next(iter(split))\n",
    "\n",
    "    _save_organized_data_info(split.classes, indices_tr, indices_val)\n",
    "    \n",
    "    return indices_tr, indices_val, split.classes\n",
    "\n",
    "def _save_organized_data_info(classes, indices_tr, indices_val):\n",
    "    info = {\n",
    "        'dir_tr': NEW_TRAIN_DIR,\n",
    "        'num_tr': len(indices_tr),\n",
    "        'dir_val': NEW_VAL_DIR,\n",
    "        'num_val': len(indices_val),\n",
    "        'num_distinct_cls': len(classes),\n",
    "    }\n",
    "    save_organized_data_info(info, IMGS_DIM_2D[0])\n",
    "\n",
    "def save_organized_data_info(info, imgs_dim_1d):\n",
    "    with open(_organized_data_info_file_dim(imgs_dim_1d), 'w') as f:\n",
    "        dump(info, f)\n",
    "\n",
    "def load_organized_data_info(imgs_dim_1d):\n",
    "    with open(_organized_data_info_file_dim(imgs_dim_1d), 'r') as f:\n",
    "        return load(f)\n",
    "    \n",
    "def _organized_data_info_file_dim(imgs_dim_1d):\n",
    "    split = ORGANIZED_DATA_INFO_FILE.split('.')\n",
    "    split[0] += str(imgs_dim_1d)\n",
    "    return join(DATA_DIR, '.'.join(split))\n",
    "\n",
    "def _save_images_to_dir(dest_dir, src_paths, labels, distinct_classes):\n",
    "\n",
    "    _make_dir_tree(dest_dir, distinct_classes)\n",
    "\n",
    "    for src_path, label in zip(src_paths, labels):\n",
    "        dest_path = join(join(dest_dir, str(label)), basename(src_path))\n",
    "        scaled_cropped_image = _save_scaled_cropped_img(src_path, dest_path)\n",
    "        \n",
    "def _make_dir_tree(dir_, classes):\n",
    "    mkdir(dir_)\n",
    "    for class_ in classes:\n",
    "        class_dir = join(dir_, str(class_))\n",
    "        mkdir(class_dir)\n",
    "        \n",
    "def _save_scaled_cropped_img(src, dest):\n",
    "    image = load_img(src)\n",
    "    image = fit(image, IMGS_DIM_2D, method=LANCZOS)\n",
    "    image.save(dest)\n",
    "    return image\n",
    "\n",
    "def _organize_test_dir():\n",
    "    makedirs(NEW_TEST_DIR)\n",
    "\n",
    "    num_test_samples = 0\n",
    "    for name in listdir(TEST_DIR):\n",
    "        src_path = abspath(join(TEST_DIR, name))\n",
    "        dest_path = join(NEW_TEST_DIR, name)\n",
    "        try:\n",
    "            _save_scaled_cropped_img(src_path, dest_path)\n",
    "            num_test_samples += 1\n",
    "        except IOError:\n",
    "            pass\n",
    "\n",
    "    _append_num_te_to_organized_data_info(num_test_samples)\n",
    "    \n",
    "def _append_num_te_to_organized_data_info(num_test_samples):\n",
    "    data_info = load_organized_data_info(IMGS_DIM_2D[0])\n",
    "    data_info['dir_te'] = dirname(NEW_TEST_DIR)\n",
    "    data_info['num_te'] = num_test_samples\n",
    "    save_organized_data_info(data_info, IMGS_DIM_2D[0])\n",
    "    \n",
    "\n",
    "def init_directory_generator(\n",
    "        gen, dir_, batch_size, target_size=IMGS_DIM_2D,\n",
    "        class_mode='categorical', shuffle_=True):\n",
    "\n",
    "    return gen.flow_from_directory(\n",
    "        dir_,\n",
    "        class_mode=class_mode,\n",
    "        batch_size=batch_size,\n",
    "        target_size=target_size,\n",
    "        shuffle=shuffle_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# _organize_train_dir()\n",
    "# _organize_test_dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data provider stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "from random import shuffle\n",
    "from itertools import combinations, chain\n",
    "from math import ceil\n",
    "\n",
    "def generators(dir_tr, dir_val, dir_test,\n",
    "               batch_size, num_groups_tr, num_groups_val, num_samples_per_cls=2, num_samples_per_cls_val=None):\n",
    "\n",
    "    gen_tr = PairsImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        rotation_range=180,\n",
    "        zoom_range=0.2,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.3,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='reflect'\n",
    "    )\n",
    "    \n",
    "    gen_val = PairsImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True\n",
    "    )\n",
    "\n",
    "    sample = np.array(apply_to_images_in_subdirs(dir_tr, load_img_arr, num_samples_per_cls=num_samples_per_cls))\n",
    "    gen_tr.fit(sample)\n",
    "    gen_val.fit(sample)\n",
    "\n",
    "    gen_tr = gen_tr.flow_from_directory(\n",
    "        dir_tr, batch_size=batch_size, num_groups=num_groups_tr)\n",
    "    \n",
    "    gen_val = gen_val.flow_from_directory(\n",
    "        dir_val, batch_size=batch_size, num_groups=num_groups_val,\n",
    "        num_samples_per_cls=num_samples_per_cls_val)\n",
    "    \n",
    "    return gen_tr, gen_val\n",
    "\n",
    "def test_generator(dir_tr, num_samples_per_cls=2):\n",
    "    \n",
    "    gen_te = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "    \n",
    "    sample = apply_to_images_in_subdirs(dir_tr, load_img_arr, num_samples_per_cls=num_samples_per_cls)\n",
    "    sample = np.array(sample)\n",
    "    \n",
    "    gen_te.fit(sample)\n",
    "    return gen_te\n",
    "\n",
    "class PairsImageDataGenerator(ImageDataGenerator):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(PairsImageDataGenerator, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def flow(self, X, y=None, batch_size=32, shuffle=True, seed=None,\n",
    "             save_to_dir=None, save_prefix='', save_format='jpeg',\n",
    "             num_groups=43, num_samples_per_cls=None):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def flow_from_directory(\n",
    "            self, dir_, target_size=(256, 256), color_mode='rgb',\n",
    "            classes=None, class_mode='categorical', batch_size=32,\n",
    "            shuffle=True, seed=None, save_to_dir=None, save_prefix='',\n",
    "            save_format='jpeg', num_groups=43, num_samples_per_cls=None):\n",
    "\n",
    "        return PairsDirectoryIterator(\n",
    "            dir_, num_groups, self, batch_size, num_samples_per_cls)\n",
    "\n",
    "class PairsDirectoryIterator(object):\n",
    "\n",
    "    def __init__(self, dir_, num_groups, image_data_generator,\n",
    "                 batch_size=32, num_samples_per_cls=None):\n",
    "\n",
    "        paths, y = self._get_paths_labels_from_dir(dir_, num_samples_per_cls)\n",
    "        self.paths = paths\n",
    "        self.y = y\n",
    "        self.num_groups = num_groups\n",
    "        self.batch_size = batch_size\n",
    "        self._init_pairs_generator()\n",
    "        self.image_data_generator = image_data_generator\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_paths_labels_from_dir(dir_, num_per_cls):\n",
    "        def path_label(p): return [p, basename(dirname(p))]\n",
    "        paths_labels = apply_to_images_in_subdirs(dir_, path_label, num_per_cls)\n",
    "        paths_labels = np.array(paths_labels)\n",
    "        return paths_labels[:, 0], paths_labels[:, 1].astype(int)\n",
    "\n",
    "    def _init_pairs_generator(self):\n",
    "        self.pairs_generator = pairs_generator(\n",
    "            self.paths, self.y, self.batch_size,\n",
    "            lambda a, b: [a, b], self.num_groups)\n",
    "\n",
    "    def iter(self):\n",
    "        return self\n",
    "\n",
    "    def next(self):\n",
    "        with self.lock:\n",
    "            try:\n",
    "                paths_batch, y_batch = next(self.pairs_generator)\n",
    "            except StopIteration:\n",
    "\n",
    "                self._init_pairs_generator()\n",
    "                paths_batch, y_batch = next(self.pairs_generator)\n",
    "\n",
    "        X_batch = []\n",
    "        for path_a, path_b in paths_batch:\n",
    "            image_a, image_b = load_img_arr(path_a), load_img_arr(path_b)\n",
    "            image_a = self._std_random_transform_img(image_a)\n",
    "            image_b = self._std_random_transform_img(image_b)\n",
    "            X_batch.append([image_a, image_b])\n",
    "        X_batch = np.array(X_batch)\n",
    "\n",
    "        return [X_batch[:, 0], X_batch[:, 1]], y_batch\n",
    "\n",
    "    def _std_random_transform_img(self, img):\n",
    "        img = self.image_data_generator.random_transform(img)\n",
    "        return self.image_data_generator.standardize(img)\n",
    "    \n",
    "def apply_to_images_in_subdirs(parent_dir, func, num_samples_per_cls=None, **kwargs):\n",
    "    results = []\n",
    "    for cls_dir_name in listdir(parent_dir):\n",
    "        cls_dir = abspath(join(parent_dir, cls_dir_name))\n",
    "        r = _apply_to_first_n_in_dir(func, cls_dir, num_samples_per_cls, **kwargs)\n",
    "        results += r\n",
    "    return results\n",
    "\n",
    "def _apply_to_first_n_in_dir(func, dir_, num_samples_per_cls, **kwargs):\n",
    "    if not isdir(dir_):\n",
    "        return []\n",
    "    results = []\n",
    "    for path in listdir(dir_)[:num_samples_per_cls]:\n",
    "        abspath_ = abspath(join(dir_, path))\n",
    "        result = func(abspath_, **kwargs)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "def pairs_generator(X, y, batch_size, pair_func, num_groups):\n",
    "    grouped_indices = _split_into_groups(y, num_groups)\n",
    "    merged_combinations = _merge_within_groups_combinations(grouped_indices)\n",
    "\n",
    "    while True:\n",
    "        X_batch, y_batch = [], []\n",
    "\n",
    "        for _ in range(batch_size):\n",
    "            try:\n",
    "                pair_indices = next(merged_combinations)\n",
    "            except StopIteration:\n",
    "                return\n",
    "\n",
    "            index_a, index_b = int(pair_indices[0]), int(pair_indices[1])\n",
    "            X_batch.append(pair_func(X[index_a], X[index_b]))\n",
    "            y_batch.append(int(y[index_a] == y[index_b]))\n",
    "\n",
    "        yield np.array(X_batch), np.array(y_batch)\n",
    "\n",
    "def _split_into_groups(y, num_groups):\n",
    "    groups = [[] for _ in range(num_groups)]\n",
    "    group_index = 0\n",
    "\n",
    "    for cls in set(y):\n",
    "        this_cls_indices = np.where(y == cls)[0]\n",
    "        num_cls_samples = len(this_cls_indices)\n",
    "\n",
    "#         num_cls_split_groups = ceil(num_cls_samples / 500)\n",
    "        num_cls_split_groups = max(1, ceil(num_cls_samples / 500))\n",
    "        split = np.array_split(this_cls_indices, num_cls_split_groups)\n",
    "\n",
    "        for cls_group in split:\n",
    "            groups[group_index] = np.hstack((groups[group_index], cls_group))\n",
    "            group_index = (group_index + 1) % num_groups\n",
    "\n",
    "    return groups\n",
    "\n",
    "def _merge_within_groups_combinations(grouped_indices):\n",
    "    for gi in grouped_indices:\n",
    "        shuffle(gi)\n",
    "    group_combinations = [combinations(gi, 2) for gi in grouped_indices]\n",
    "    shuffle(group_combinations)\n",
    "    return chain.from_iterable(group_combinations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and train siamese net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Convolution2D \n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import Input\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "SIAMESE_MODEL_FILE = join(MODELS_DIR, 'siamese.h5')\n",
    "\n",
    "IMGS_DIM_3D = (3, 256, 256)\n",
    "BATCH_SIZE = 32\n",
    "MAX_EPOCHS = 20 #500\n",
    "\n",
    "TRAIN_SAMPLES_PER_EPOCH = 10000\n",
    "VAL_SAMPLES_PER_EPOCH = 1000\n",
    "TEST_SAMPLES_TOTAL = 1000\n",
    "\n",
    "NUM_GROUPS_TR = NUM_GROUPS_VAL = 1\n",
    "NUM_SAMPLES_PER_CLS = 2\n",
    "        \n",
    "data_info = load_organized_data_info(IMGS_DIM_3D[1])\n",
    "dir_tr = data_info['dir_tr']\n",
    "dir_val = data_info['dir_val']\n",
    "dir_test = data_info['dir_test']\n",
    "    \n",
    "def train_siamese_net():\n",
    "    \n",
    "    model = siamese_net()\n",
    "    \n",
    "    print \"Training model\"\n",
    "    \n",
    "    model.fit_generator(\n",
    "        generator=gen_tr,\n",
    "        nb_epoch=MAX_EPOCHS,\n",
    "#         samples_per_epoch=data_info['num_tr'],\n",
    "        samples_per_epoch=TRAIN_SAMPLES_PER_EPOCH,\n",
    "        validation_data=gen_val,\n",
    "#         nb_val_samples=data_info['num_val'],\n",
    "        nb_val_samples=VAL_SAMPLES_PER_EPOCH,\n",
    "        callbacks=[ModelCheckpoint(SIAMESE_MODEL_FILE, save_best_only=True)],\n",
    "        verbose=2\n",
    "    )\n",
    "        \n",
    "def build_siamese_net():\n",
    "    \n",
    "    print \"Building siamese net\"\n",
    "    \n",
    "    processor = _shared_net()\n",
    "    \n",
    "    input_1 = Input(shape=IMGS_DIM_3D)\n",
    "    input_2 = Input(shape=IMGS_DIM_3D)\n",
    "    \n",
    "    processed_1 = processor(input_1)\n",
    "    processed_2 = processor(input_2)\n",
    "    \n",
    "    distance = Lambda(_euclidean_distance, output_shape=_eucl_dist_output_shape)([processed_1, processed_2])\n",
    "    \n",
    "    model = Model(input=[input_1, input_2], output=distance)\n",
    "    \n",
    "    model.compile(loss=_contrastive_loss, optimizer='rmsprop')\n",
    "    \n",
    "    return model\n",
    "    \n",
    "def _shared_net():\n",
    "    \n",
    "    print \"Building shared net\"\n",
    "    \n",
    "    # input image dimensions\n",
    "#     img_colours, img_rows, img_cols = IMGS_DIM_3D\n",
    "\n",
    "    # number of convolutional filters to use\n",
    "    nb_filters = 32\n",
    "\n",
    "    # size of pooling area for max pooling\n",
    "    nb_pool = 2\n",
    "\n",
    "    # convolution kernel size\n",
    "    nb_conv = 3\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(nb_filters, nb_conv, nb_conv,  activation='relu',\n",
    "                            input_shape=IMGS_DIM_3D, border_mode='valid'))\n",
    "#     model.add(BatchNormalization(axis=1, mode=2))\n",
    "    model.add(Convolution2D(nb_filters, nb_conv, nb_conv, activation='relu'))\n",
    "#     model.add(BatchNormalization(axis=1, mode=2))\n",
    "    model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(64, input_shape=IMGS_DIM_3D, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    return model\n",
    "\n",
    "def _euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
    "\n",
    "def _eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return shape1\n",
    "                  \n",
    "def _contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
    "\n",
    "def compute_accuracy(y_pred, y_true):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return y_true[y_pred.ravel() < 0.5].mean()\n",
    "\n",
    "def test_siamese_net(model, gen_te):\n",
    "    gen_te = test_generator(dir_tr=dir_tr, num_per_cls=NUM_SAMPLES_PER_CLS)\n",
    "    model.evaluate_generator(gen_te, val_samples=TEST_SAMPLES_TOTAL)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_tr, gen_val, gen_test = generators(dir_tr, dir_val, dir_test, NUM_GROUPS_TR, NUM_GROUPS_VAL, NUM_SAMPLES_PER_CLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = build_siamese_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train(model, gen_tr, gen_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test siamese net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test(model, gen_te)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
